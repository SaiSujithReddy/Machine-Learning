{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "5  0.260314 -0.568671  ...   -0.208254 -0.559825 -0.026398 -0.371427   \n",
       "6  0.081213  0.464960  ...   -0.167716 -0.270710 -0.154104 -0.780055   \n",
       "7 -3.807864  0.615375  ...    1.943465 -1.015455  0.057504 -0.649709   \n",
       "8  0.851084 -0.392048  ...   -0.073425 -0.268092 -0.204233  1.011592   \n",
       "9  0.069539 -0.736727  ...   -0.246914 -0.633753 -0.120794 -0.385050   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "5 -0.232794  0.105915  0.253844  0.081080    3.67      0  \n",
       "6  0.750137 -0.257237  0.034507  0.005168    4.99      0  \n",
       "7 -0.415267 -0.051634 -1.206921 -1.085339   40.80      0  \n",
       "8  0.373205 -0.384157  0.011747  0.142404   93.20      0  \n",
       "9 -0.069733  0.094199  0.246219  0.083076    3.68      0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries \n",
    "import pandas as pd\n",
    "\n",
    "#import display for DataFrame usage\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the credit card transactions dataset\n",
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "# On Success - Display the first ten records\n",
    "display(data.head(n=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 284807\n"
     ]
    }
   ],
   "source": [
    "# Count total number of transactions \n",
    "print \"Total number of records: {}\".format(data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.describe())\n",
    "\n",
    "#storing original data\n",
    "total_data = data\n",
    "# Outcomes \n",
    "data_class_outcomes = data['Class']\n",
    "#preserving only dimensions\n",
    "data.drop(['Class'], axis = 1, inplace = True)\n",
    "\n",
    "#display(data_Class)\n",
    "#display(data_Class.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy_score(truth, pred):\n",
    "    \"\"\" Returns accuracy score for input truth and predictions. \"\"\"\n",
    "    \n",
    "    # Ensure that the number of predictions matches number of outcomes\n",
    "    if len(truth) == len(pred): \n",
    "        \n",
    "        # Calculate and return the accuracy as a percent\n",
    "        return \"Predictions have an accuracy of {:.2f}%.\".format((truth == pred).mean()*100)\n",
    "    \n",
    "    else:\n",
    "        return \"Number of predictions does not match number of outcomes!\"\n",
    "    \n",
    "    \n",
    "from sklearn.metrics import r2_score\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    score = r2_score(y_true, y_predict)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing split was successful.\n"
     ]
    }
   ],
   "source": [
    "#from sklearn import cross_validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, X_test, y_train, y_test = cross_validation.train_test_split(data,data_class_outcomes,test_size=0.2,random_state=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,data_class_outcomes,test_size=0.2, random_state=42)\n",
    "# Success\n",
    "print \"Training and testing split was successful.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def fit_model(X, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    cv_sets = ShuffleSplit(X.shape[0], n_iter=10, test_size = 0.20, random_state = 0)\n",
    "\n",
    "    # TODO: Create a decision tree regressor object\n",
    "    regressor = DecisionTreeRegressor()\n",
    "\n",
    "    # TODO: Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "    params = {'max_depth':range(1,11)}\n",
    "\n",
    "    # TODO: Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "    # TODO: Create the grid search object\n",
    "    grid = GridSearchCV(regressor,params,cv=cv_sets,scoring=scoring_fnc)\n",
    "\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    grid = grid.fit(X, y)\n",
    "\n",
    "    # Return the optimal model after fitting the data\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter 'max_depth' is 6 for the optimal model.\n"
     ]
    }
   ],
   "source": [
    "# Fit the training data to the model using grid search\n",
    "reg = fit_model(X_train, y_train)\n",
    "\n",
    "# Produce the value for 'max_depth'\n",
    "print \"Parameter 'max_depth' is {} for the optimal model.\".format(reg.get_params()['max_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from time import time\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    results = {}\n",
    "    \n",
    "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
    "    start = time() # Get start time\n",
    "    \n",
    "    x1 = X_train[:sample_size]\n",
    "    y1 = y_train[:sample_size]\n",
    "    \n",
    "    learner.fit(x1,y1)\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "        \n",
    "    # TODO: Get the predictions on the test set,\n",
    "    #       then get predictions on the first 300 training samples\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the total prediction time\n",
    "    results['pred_time'] = end - start \n",
    "            \n",
    "    # TODO: Compute accuracy on the first 300 training samples\n",
    "    results['acc_train'] = accuracy_score(y_train[:300],predictions_train)\n",
    "        \n",
    "    # TODO: Compute accuracy on test set\n",
    "    results['acc_test'] = accuracy_score(y_test,predictions_test)\n",
    "    \n",
    "    # TODO: Compute F-score on the the first 300 training samples\n",
    "    results['f_train'] = fbeta_score(y_train[:300],predictions_train,average='weighted',beta=0.5)\n",
    "        \n",
    "    # TODO: Compute F-score on the test set\n",
    "    results['f_test'] = fbeta_score(y_test,predictions_test,average='weighted',beta=0.5)\n",
    "       \n",
    "    # Success\n",
    "    print \"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size)\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier trained on 2278 samples.\n",
      "DecisionTreeClassifier trained on 22784 samples.\n",
      "DecisionTreeClassifier trained on 227845 samples.\n",
      "LogisticRegression trained on 2278 samples.\n",
      "LogisticRegression trained on 22784 samples.\n",
      "LogisticRegression trained on 227845 samples.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Initialize the three models\n",
    "# random state is the seed of the pseudo random number generator to use when shuffling the data\n",
    "clf_A = tree.DecisionTreeClassifier(random_state=42)\n",
    "#clf_B = svm.SVC(random_state=2)\n",
    "clf_C = linear_model.LogisticRegression(random_state=42)\n",
    "# TODO: Calculate the number of samples for 1%, 10%, and 100% of the training data\n",
    "samples_1 = y_train.size/100\n",
    "samples_10 = y_train.size/10\n",
    "samples_100 = y_train.size\n",
    "\n",
    "# Collect results on the learners\n",
    "results = {}\n",
    "for clf in [clf_A, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
    "        results[clf_name][i] = \\\n",
    "        train_predict(clf, samples, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Run metrics visualization for the three supervised learning models chosen\n",
    "#vs.evaluate(results, accuracy, fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LogisticRegression': {0: {'pred_time': 0.005942106246948242, 'f_test': 0.99864700136753803, 'train_time': 0.03371691703796387, 'acc_train': 1.0, 'acc_test': 0.99884133281837018, 'f_train': 1.0}, 1: {'pred_time': 0.0030548572540283203, 'f_test': 0.99824634545944713, 'train_time': 0.5683538913726807, 'acc_train': 1.0, 'acc_test': 0.99856044380464171, 'f_train': 1.0}, 2: {'pred_time': 0.0030450820922851562, 'f_test': 0.99887326979851165, 'train_time': 6.903032064437866, 'acc_train': 1.0, 'acc_test': 0.99899933288859244, 'f_train': 1.0}}, 'DecisionTreeClassifier': {0: {'pred_time': 0.011923074722290039, 'f_test': 0.99829791790613953, 'train_time': 0.041480064392089844, 'acc_train': 1.0, 'acc_test': 0.99833222148098733, 'f_train': 1.0}, 1: {'pred_time': 0.005605936050415039, 'f_test': 0.99884437341656596, 'train_time': 0.3776121139526367, 'acc_train': 1.0, 'acc_test': 0.99896422176187638, 'f_train': 1.0}, 2: {'pred_time': 0.008964061737060547, 'f_test': 0.99910809852885496, 'train_time': 22.51976203918457, 'acc_train': 1.0, 'acc_test': 0.99905199957866653, 'f_train': 1.0}}}\n"
     ]
    }
   ],
   "source": [
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred_time': 0.0030450820922851562, 'f_test': 0.99887326979851165, 'train_time': 6.903032064437866, 'acc_train': 1.0, 'acc_test': 0.99899933288859244, 'f_train': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print results['LogisticRegression'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred_time': 0.008964061737060547, 'f_test': 0.99910809852885496, 'train_time': 22.51976203918457, 'acc_train': 1.0, 'acc_test': 0.99905199957866653, 'f_train': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print results['DecisionTreeClassifier'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56855,     9],\n",
       "       [   20,    78]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classifier = DTC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "clf_A = tree.DecisionTreeClassifier(random_state=42,max_depth=6)\n",
    "clf_A.fit(X_train,y_train)\n",
    "y_pred = clf_A.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56962\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56830,    34],\n",
       "       [   20,    78]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56853,    11],\n",
       "       [   46,    52]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classifier = LR\n",
    "from sklearn import linear_model\n",
    "clf_C = linear_model.LogisticRegression(random_state=42)\n",
    "clf_C.fit(X_train,y_train)\n",
    "y_pred = clf_C.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56862,     2],\n",
       "       [   20,    78]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classifier = RFC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_B = RandomForestClassifier(n_estimators=98)\n",
    "clf_B.fit(X_train, y_train)\n",
    "y_pred = clf_B.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named costcla.models",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-5db8af57bcae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcostcla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBayesMinimumRiskClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclf_D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesMinimumRiskClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf_D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named costcla.models"
     ]
    }
   ],
   "source": [
    "from costcla.models import BayesMinimumRiskClassifier\n",
    "clf_D = BayesMinimumRiskClassifier()\n",
    "clf_D.fit(X_train, y_train)\n",
    "y_pred = clf_D.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARkAAAD0CAYAAACvvVL/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9fd8a8ed10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(confusion_matrix(y_test, y_pred))\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
